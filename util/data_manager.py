from datetime import timedelta
from typing import Any, Dict, Optional, Iterable

from util.logger import Log, Color
from util.nowtime import TaiwanTime
from util.supabase_client import supabase


class DataManager:
    """
    ä¾ç…§ stock_id / date / data / type(é¢å‘) å­˜æ”¾æ–¼ Supabaseï¼Œä¸¦åœ¨æœ¬åœ°è¨˜æ†¶é«”ä»¥é™£åˆ—/å­—å…¸å¿«å–ã€‚
    äº¦å¯é€é key_fields/table_name è‡ªè¨‚ä¸»éµæ¬„ä½ï¼ˆä¾‹å¦‚æ–°èæƒ…ç·’ä»¥ url ç‚ºä¸»éµï¼‰ã€‚

    - basic_data æ¯æ—¥ 17:00 å¾Œæ›´æ–°
    - chip_data  æ¯æ—¥ 21:00 å¾Œæ›´æ–°
    """

    STOCK_SCORE_TABLE = "stockScores"
    NEWS_TABLE = "newsScores"
    BASIC_UPDATE_HOUR = 17
    CHIP_UPDATE_HOUR = 21
    _local_cache: Dict[str, Dict[str, Any]] = {}
    # çµæ§‹: {table: {cache_key: payload}}

    @staticmethod
    def _normalize_stock_id(stock_id: Optional[str]) -> str:
        """çµ±ä¸€ç§»é™¤ .TW ä¹‹é¡çš„å¾Œç¶´ã€‚"""
        if not stock_id:
            return ""
        return stock_id.split(".")[0]

    @classmethod
    def _resolve_score_date(cls, score_type: str, score_date: Optional[str] = None) -> str:
        """
        æ±ºå®šè©²ç­†è³‡æ–™çš„ç´€éŒ„æ—¥æœŸã€‚
        è‹¥åœ¨æ›´æ–°æ™‚é»å‰å‘¼å«ï¼Œæœƒè‡ªå‹•å›å¡«åˆ°å‰ä¸€æ—¥ï¼Œé¿å…æ—¥æœŸèˆ‡å¯¦éš›æ›´æ–°æ™‚é–“ä¸ä¸€è‡´ã€‚
        """
        if score_date:
            return score_date

        now = TaiwanTime.now()
        cutoff = cls.CHIP_UPDATE_HOUR if score_type == "chip" else cls.BASIC_UPDATE_HOUR
        record_date = now.date()
        if now.hour < cutoff:
            record_date -= timedelta(days=1)
        return record_date.strftime("%Y-%m-%d")

    @classmethod
    def _make_cache_key(cls, key_fields: Dict[str, Any]) -> str:
        return "|".join(f"{k}:{key_fields[k]}" for k in sorted(key_fields))

    @classmethod
    def _cache_get(cls, table: str, key_fields: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        cache_key = cls._make_cache_key(key_fields)
        return cls._local_cache.get(table, {}).get(cache_key)

    @classmethod
    def _cache_set(cls, table: str, key_fields: Dict[str, Any], payload: Dict[str, Any]) -> None:
        cache_key = cls._make_cache_key(key_fields)
        cls._local_cache.setdefault(table, {})[cache_key] = payload

    @classmethod
    def save_score(
        cls,
        stock_id: Optional[str],
        data: Dict[str, Any],
        score_type: str,
        score_date: Optional[str] = None,
        direction: Optional[Any] = None,
        table_name: Optional[str] = None,
        key_fields: Optional[Dict[str, Any]] = None,
        conflict_keys: Optional[Iterable[str]] = None,
        flatten_data: bool = False,
        include_data: bool = True,
    ) -> Optional[Dict[str, Any]]:
        """
        ä»¥ upsert æ–¹å¼å­˜å…¥ Supabaseï¼Œé¿å…é‡è¤‡æ’å…¥ï¼ŒåŒæ­¥å¯«å…¥æœ¬åœ°å¿«å–ã€‚
        å¯é€é key_fields/table_name è‡ªè¨‚ä¸»éµæ¬„ä½ã€‚è‹¥ include_data=Falseï¼Œå‰‡ä¸å­˜ data jsonã€‚
        """
        table = table_name or cls.STOCK_SCORE_TABLE
        if key_fields is None:
            record_date = cls._resolve_score_date(score_type, score_date)
            key_fields = {
                "stock_id": cls._normalize_stock_id(stock_id),
                "date": record_date,
                "type": score_type,
            }
            conflict_keys = conflict_keys or ("stock_id", "date", "type")
        else:
            conflict_keys = conflict_keys or tuple(key_fields.keys())

        payload: Dict[str, Any] = dict(key_fields)
        if include_data:
            payload["data"] = data
        if flatten_data:
            payload.update(data)
        if direction is not None:
            payload["direction"] = direction

        # local cache first
        cls._cache_set(table, key_fields, payload)

        try:
            response = (
                supabase.table(table)
                .upsert(payload, on_conflict=",".join(conflict_keys))
                .execute()
            )
            return getattr(response, "data", None)
        except Exception as exc:
            Log(f"ğŸ”´ [DataManager] å„²å­˜å¤±æ•—: {exc}", color=Color.RED)
            return None

    @classmethod
    def get_score(
        cls,
        stock_id: Optional[str],
        score_type: str,
        score_date: Optional[str] = None,
        table_name: Optional[str] = None,
        key_fields: Optional[Dict[str, Any]] = None,
    ) -> Optional[Dict[str, Any]]:
        """
        å–å›æŒ‡å®šæ—¥æœŸèˆ‡é¢å‘çš„ç´€éŒ„ï¼›è‹¥æœªæŒ‡å®šæ—¥æœŸå‰‡å¥—ç”¨æ™‚é–“é‚è¼¯ã€‚
        å…ˆæŸ¥æœ¬åœ°å¿«å–ï¼Œç„¡è³‡æ–™å†æŸ¥ Supabaseã€‚å¯é€é key_fields/table_name è‡ªè¨‚ä¸»éµæ¬„ä½ã€‚
        """
        table = table_name or cls.STOCK_SCORE_TABLE
        if key_fields is None:
            record_date = cls._resolve_score_date(score_type, score_date)
            key_fields = {
                "stock_id": cls._normalize_stock_id(stock_id),
                "type": score_type,
                "date": record_date,
            }
        else:
            record_date = key_fields.get("date")

        cached = cls._cache_get(table, key_fields)
        if cached:
            return cached

        try:
            query = supabase.table(table).select("*")
            for key, value in key_fields.items():
                query = query.eq(key, value)
            response = query.execute()
            if getattr(response, "data", None):
                payload = response.data[0]
                cls._cache_set(table, key_fields, payload)
                return payload
            return None
        except Exception as exc:
            Log(f"ğŸ”´ [DataManager] è®€å–å¤±æ•—: {exc}", color=Color.RED)
            return None
